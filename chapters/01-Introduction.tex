%!TEX root = ../main.tex

\chapter{Introduction}\label{cha:introduction}

Deep Learning is a subclass of Machine Learning that has achieved state of the art results in a wide variety of domains.
They were originally proposed by McCulloch and Pitts in 1943 as a model for how the brain processes information \cite{McCulloch_Pitts_1943}.
In 1957, Rosenblatt created the Perceptron \cite{Rosenblatt_1957, Rosenblatt_1958}, however it was shown that it is impossible for these to learn the simple XOR function \cite{Minsky_Papert_1988}.
In the 1980's neural networks became popular again and Rumelhart, Hinton, and Williams wrote a famous paper outlining the backpropagation algorithm for training networks of neuron-like units \cite{Rumelhart_Hinton_Williams_1986}.
This algorithm remains at the core of all deep learning today.


\section{Neural Networks}\label{sec:neural_network_int}
The goal of a neural network is to approximate some function $f^*$.
Suppose there is a classifier $y=f^*(\bm{x})$ which maps inputs $\bm{x}$ to category $y$.
A neural network defines a mapping $\bm{y}=f(\bm{x}, \bm{\theta})$ and attempts to learn the values of parameter $\bm{\theta}$ that best approximate $f^*$.
The model is usually depicted as an acyclic graph which represents how several functions are composed together.
For example, three functions $f_1, f_2, f_3$ may be chained together such that $f(\bm{x}) = f_3(f_2(f_1(\bm{x})))$.

We refer to these networks as neural because they are inspired by the brain.
A neural network is a collection of connected nodes (simplified versions of  biological neurons).
A connection between two nodes (equivalent of a biological synapse) can transfer data from one node to the next.
The signal processed between two nodes is a real valued number, and the output is a non-linear function (see Section \ref{subsec:activation_function}) of the sum of its inputs.
Figure \ref{fig:neural_net} shows a simple neural network with 2 layers.

\begin{figure}[hbtp!]
    \centering
    \subfloat[A basic neural network]{\includestandalone[width = 0.5\textwidth]{./img/tikz/neural_net}\label{fig:neural_net}}
\end{figure}

In this diagram, we have 1 input layer, 1 hidden layer and 1 output layer and the network contains two functions $f_1, f_2$ that are chained together such that $f(\bm{x}) = f_2(f_1(\bm{x}))$.
The hidden layer $\bm{h}$ is given by:

\begin{equation}
    \bm{h} = f_1(\bm{x}; \bm{W_1}, \bm{b_1}) = g(\bm{W_1}^\top \cdot \bm{x} + \bm{b_1})
    \label{eq:hidden_layer}
\end{equation}
.
The output layer $\bm{y}$ is given by:

\begin{equation}
    \bm{y} = f_2(\bm{h}; \bm{W_2}, \bm{b_2}) = g(\bm{W_2}^\top \cdot \bm{h} + \bm{b_2})
    \label{eq:output_layer}
\end{equation}

Where $g$ is a non-linear activation function (see Section \ref{subsec:activation_function}) , $\bm{W_1}, \bm{W_2}$ are weight matrices and $\bm{b_1}, \bm{b_2}$ are bias vectors.
Thus each node is non-linear function of the sum of its inputs, as mentioned earlier.

A way of evaluating the neural network is now needed.
The MSE loss function over the training set $\mathbb{X}$ is defined as:

\begin{equation}
    J(\bm{\theta}) = \frac{1}{4} \sum_{\bm{x} \in \mathbb{X}} (f^*(\bm{x}) - f(\bm{x}; \bm{\theta}))^2
    \label{mse_loss_function}
\end{equation}

Where $\bm{\theta}$ represents all learnable parameters $\bm{W_1}, \bm{W_2}, \bm{b_1}, \bm{b_2}$.
Now $J(\bm{\theta})$ must be minimised with respect to $\bm{W_1}, \bm{W_2}, \bm{b_1}, \bm{b_2}$.
In a real life example, the model will have many layers and potentially billions of parameters.
This makes finding a global minimum in the weight space impossible and gradient descent methods must be used.

\subsection{Activation Functions}\label{subsec:activation_function}

Activation functions can be linear or non-linear.
However, a deep neural network that uses only linear activations is equivalent to a single layer network, and is therefore unable to approximate the complex functions we require.
There are many different non-linear activation functions used by researchers including ReLU \cite{Jarrett_Kavukcuoglu_Lecun}, tanh \cite{LeCun_Bottou_Orr_Muller_1998}, Sigmoid \cite{Han_Moraga_1995}, SWISH \cite{Ramachandran_Zoph_Le_2017} and other variations.
More recently, work has been done to automatically learn different combinations of base activation functions \cite{Manessi_Rozza_2018}.

\begin{figure}[hbtp!]
    \centering
    \includegraphics[width=0.45\textwidth]{./img/ReLU.png}
    \includegraphics[width=0.45\textwidth]{./img/tanh.png}
    \caption{The Rectified Linear Unit (ReLU) and $\tanh$ activation functions}
    \label{fig:ReLU_tanh}
\end{figure}


\section{Problem Description}\label{sec:problem_description_int}

Deep learning has an important role to play in modern health care due to the large amounts of data it produces.
It has actually been suggested that genomics alone will either equal or surpass other data intensive fields within the next decade \cite{Stephens_Lee_Faghri_Campbell_Zhai_Efron_Iyer_Schatz_Sinha_Robinson_2015}.
The analysis of natural images is particularly relevant due to the high number of scans that are performed regularly.
Many different tasks can be performed on natural images including classification, localisation, segmentation, noise reduction and feature extraction.
This report will focus on segmentation of PET Scans.

\subsection{PET Scans}\label{subsec:pet_scan_int}
Positron Emission Tomography (PET) scans are used to produce 3 Dimensional images of the human body and are often combined with CT scans (called PET-CT) or MRI scans (PET-MRI) in order to increase the level of detail.
PET scans are particularly useful because they describe how certain parts of the body are functioning in addition to their physical appearance.
PET scans are most commonly used for investigating confirmed cases of cancer to determine how far the cancer has spread and how well it's responding to treatment \cite{Radiology_ACR, PET_scan}.
The procedure is as follows:

\begin{itemize}
    \item A radioactive tracer (often glucose based) is introduced to the patient either by injection into the bloodstream, swallowing or inhalation as a gas.
    \item For a glucose based tracer, cells in the body with a high metabolic rate will accumulate the tracer.
    \item The tracer gives off a small amount of energy in the form of gamma rays which is detected by the scanner.
    \item A computer then produces a 3D image in which hotspots indicate a large amount of tracer accumulation and therefore a high level of metabolic activity.
\end{itemize}

Figures \ref{fig:positive} and \ref{fig:negative} show a selection of slices from PET scans with and without cancer respectively.
A slice is a 2D crossection taken from the 3D scan.

\begin{figure}[hbtp!]
    \centering
    \includegraphics[width=\textwidth]{./img/positive.png}
    \caption{PET Scan slices that do contain Cancer}
    \label{fig:positive}
\end{figure}

\begin{figure}[hbtp!]
    \centering
    \includegraphics[width=\textwidth]{./img/negative.png}
    \caption{PET Scan slices that do not contain Cancer}
    \label{fig:negative}
\end{figure}


\subsection{Current Data}\label{subsec:current_data_intro}

The data that has been obtained consists of approximately 400 PET scans of patients who all have esophageal cancer \cite{Enzinger_Mayer_2003}.
The aim is to perform segmentation of the scans to highlight the cancers, however the data is only partially labelled.
In Figure \ref{fig:ground_truth} PET scan slices that contain cancer are shown (similar to Figure \ref{fig:positive}).
In addition, a ground truth area has been highlighted.
This area was selected by an expert such that it definitely contains all the cancer from the scan.
It is important to note that not all of this area is cancerous; it can be seen from the scans that often only a small portion of the highlighted area is actually a cancer.

\begin{figure}[hbtp!]
    \centering
    \includegraphics[width=\textwidth]{./img/ground_truth.png}
    \caption{PET Scan slices with ground truth highlighted}
    \label{fig:ground_truth}
\end{figure}

The first stage of research is to replicate the ground truth areas located by experts.
Once these can be found automatically, further work can be done to more accurately locate the cancers.

\section{Structure}\label{sec:structure}

\begin{itemize}
    \item In Chapter \ref{cha:literature} an overview of previous literature regarding Deep Learning is given.
    \item In Chapter \ref{cha:initial_results} an outline of current work and potential future developments is outlined.
\end{itemize}